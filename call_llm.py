from langchain_community.llms import Ollama

def get_llm_output(input_string):
    """
    Get the output from the LLM (Language Model) by invoking it with the given input string.

    Parameters:
    input_string (str): The input string to be processed by the LLM.

    Returns:
    str: The output generated by the LLM.

    """
    llm = Ollama(
        model="llama3"
    )  # assuming you have Ollama installed and have llama3 model pulled with `ollama pull llama3 `

    return llm.invoke(input_string)
